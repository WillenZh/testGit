{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/deep_learn_py3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda/envs/deep_learn_py3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/anaconda/envs/deep_learn_py3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from datetime import datetime\n",
    "from xgboost import XGBRegressor\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_121\"; OpenJDK Runtime Environment (Zulu 8.20.0.5-macosx) (build 1.8.0_121-b15); OpenJDK 64-Bit Server VM (Zulu 8.20.0.5-macosx) (build 25.121-b15, mixed mode)\n",
      "  Starting server from /anaconda/envs/deep_learn_py3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/sq/d4vdcd154575z_036hk7q05c0000gn/T/tmp1paugc1p\n",
      "  JVM stdout: /var/folders/sq/d4vdcd154575z_036hk7q05c0000gn/T/tmp1paugc1p/h2o_zhangwei_started_from_python.out\n",
      "  JVM stderr: /var/folders/sq/d4vdcd154575z_036hk7q05c0000gn/T/tmp1paugc1p/h2o_zhangwei_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>08 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.16.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 6 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_zhangwei_h40mce</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.778 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         08 secs\n",
       "H2O cluster version:        3.16.0.2\n",
       "H2O cluster version age:    1 month and 6 days\n",
       "H2O cluster name:           H2O_from_python_zhangwei_h40mce\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.778 Gb\n",
       "H2O cluster total cores:    0\n",
       "H2O cluster allowed cores:  0\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.2 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing done!\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Starting h2o autoML model!\n",
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Generate predictions...\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "RMSLE H2O automl leader:  0.463231276386\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'tra': pd.read_csv('../input/air_visit_data.csv'),\n",
    "    'as': pd.read_csv('../input/air_store_info.csv'),\n",
    "    'hs': pd.read_csv('../input/hpg_store_info.csv'),\n",
    "    'ar': pd.read_csv('../input/air_reserve.csv'),\n",
    "    'hr': pd.read_csv('../input/hpg_reserve.csv'),\n",
    "    'id': pd.read_csv('../input/store_id_relation.csv'),\n",
    "    'tes': pd.read_csv('../input/sample_submission.csv'),\n",
    "    'hol': pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "    }\n",
    "\n",
    "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n",
    "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n",
    "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n",
    "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date\n",
    "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n",
    "    tmp1 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs1', 'reserve_visitors':'rv1'})\n",
    "    tmp2 = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].mean().rename(columns={'visit_datetime':'visit_date', 'reserve_datetime_diff': 'rs2', 'reserve_visitors':'rv2'})\n",
    "    data[df] = pd.merge(tmp1, tmp2, how='inner', on=['air_store_id','visit_date'])\n",
    "\n",
    "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n",
    "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n",
    "data['tra']['year'] = data['tra']['visit_date'].dt.year\n",
    "data['tra']['month'] = data['tra']['visit_date'].dt.month\n",
    "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n",
    "\n",
    "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n",
    "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n",
    "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n",
    "data['tes']['year'] = data['tes']['visit_date'].dt.year\n",
    "data['tes']['month'] = data['tes']['visit_date'].dt.month\n",
    "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date\n",
    "\n",
    "unique_stores = data['tes']['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "#sure it can be compressed...\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n",
    "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].count().rename(columns={'visitors':'count_observations'})\n",
    "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n",
    "\n",
    "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id']) \n",
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "stores['air_genre_name'] = stores['air_genre_name'].map(lambda x: str(str(x).replace('/',' ')))\n",
    "stores['air_area_name'] = stores['air_area_name'].map(lambda x: str(str(x).replace('-',' ')))\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for i in range(4):\n",
    "    stores['air_genre_name'+str(i)] = lbl.fit_transform(stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "    stores['air_area_name' +str(i)] = lbl.fit_transform(stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n",
    "\n",
    "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n",
    "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n",
    "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n",
    "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date']) \n",
    "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) \n",
    "\n",
    "train = pd.merge(train, stores, how='left', on=['air_store_id','dow']) \n",
    "test = pd.merge(test, stores, how='left', on=['air_store_id','dow'])\n",
    "\n",
    "for df in ['ar','hr']:\n",
    "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n",
    "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n",
    "\n",
    "train['id'] = train.apply(lambda r: '_'.join([str(r['air_store_id']), str(r['visit_date'])]), axis=1)\n",
    "\n",
    "train['total_reserv_sum'] = train['rv1_x'] + train['rv1_y']\n",
    "train['total_reserv_mean'] = (train['rv2_x'] + train['rv2_y']) / 2\n",
    "train['total_reserv_dt_diff_mean'] = (train['rs2_x'] + train['rs2_y']) / 2\n",
    "\n",
    "test['total_reserv_sum'] = test['rv1_x'] + test['rv1_y']\n",
    "test['total_reserv_mean'] = (test['rv2_x'] + test['rv2_y']) / 2\n",
    "test['total_reserv_dt_diff_mean'] = (test['rs2_x'] + test['rs2_y']) / 2\n",
    "\n",
    "# NEW FEATURES FROM JMBULL\n",
    "train['date_int'] = train['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "test['date_int'] = test['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "train['var_max_lat'] = train['latitude'].max() - train['latitude']\n",
    "train['var_max_long'] = train['longitude'].max() - train['longitude']\n",
    "test['var_max_lat'] = test['latitude'].max() - test['latitude']\n",
    "test['var_max_long'] = test['longitude'].max() - test['longitude']\n",
    "\n",
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "train['lon_plus_lat'] = train['longitude'] + train['latitude'] \n",
    "test['lon_plus_lat'] = test['longitude'] + test['latitude']\n",
    "\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "train['air_store_id2'] = lbl.fit_transform(train['air_store_id'])\n",
    "test['air_store_id2'] = lbl.transform(test['air_store_id'])\n",
    "\n",
    "train = train.fillna(-999)\n",
    "test = test.fillna(-999)\n",
    "\n",
    "train['visitors'] = np.log1p(train['visitors'].values)\n",
    "\n",
    "print('Pre-processing done!')\n",
    "\n",
    "htrain = h2o.H2OFrame(train)\n",
    "htest = h2o.H2OFrame(test)\n",
    "\n",
    "htrain.drop(['id', 'air_store_id', 'visit_date'])\n",
    "htest.drop(['id', 'air_store_id', 'visit_date'])\n",
    "\n",
    "x =htrain.columns\n",
    "y ='visitors'\n",
    "x.remove(y)\n",
    "\n",
    "def RMSLE(y_, pred):\n",
    "    return metrics.mean_squared_error(y_, pred)**0.5\n",
    "\n",
    "print('Starting h2o autoML model!')  \n",
    "\n",
    "aml = H2OAutoML(max_runtime_secs = 3350)\n",
    "aml.train(x=x, y =y, training_frame=htrain, leaderboard_frame = htest)\n",
    "\n",
    "print('Generate predictions...')\n",
    "htrain.drop(['visitors'])\n",
    "preds = aml.leader.predict(htrain)\n",
    "preds = preds.as_data_frame()\n",
    "print('RMSLE H2O automl leader: ', RMSLE(train['visitors'].values, preds))\n",
    "\n",
    "preds = aml.leader.predict(htest)\n",
    "preds = preds.as_data_frame()\n",
    "\n",
    "test['visitors'] = preds\n",
    "test['visitors'] = np.expm1(test['visitors']).clip(lower=0.)\n",
    "sub1 = test[['id','visitors']].copy()\n",
    "del train; del data; del htrain; del htest;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaderboard :  "
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                 </th><th style=\"text-align: right;\">  mean_residual_deviance</th><th style=\"text-align: right;\">   rmse</th><th style=\"text-align: right;\">    mae</th><th style=\"text-align: right;\">    rmsle</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_grid_0_AutoML_20180106_114457_model_0</td><td style=\"text-align: right;\">                 7.65113</td><td style=\"text-align: right;\">2.76607</td><td style=\"text-align: right;\">2.66685</td><td style=\"text-align: right;\">  1.29532</td></tr>\n",
       "<tr><td>GBM_grid_0_AutoML_20180106_114457_model_1</td><td style=\"text-align: right;\">                 7.65581</td><td style=\"text-align: right;\">2.76691</td><td style=\"text-align: right;\">2.66647</td><td style=\"text-align: right;\">  1.29519</td></tr>\n",
       "<tr><td>DRF_0_AutoML_20180106_114457             </td><td style=\"text-align: right;\">                 7.71924</td><td style=\"text-align: right;\">2.77835</td><td style=\"text-align: right;\">2.67604</td><td style=\"text-align: right;\">  1.29767</td></tr>\n",
       "<tr><td>DeepLearning_0_AutoML_20180106_114457    </td><td style=\"text-align: right;\">                12.6295 </td><td style=\"text-align: right;\">3.55381</td><td style=\"text-align: right;\">2.89632</td><td style=\"text-align: right;\">nan      </td></tr>\n",
       "<tr><td>GLM_grid_0_AutoML_20180106_114457_model_0</td><td style=\"text-align: right;\">                27.3394 </td><td style=\"text-align: right;\">5.2287 </td><td style=\"text-align: right;\">3.10546</td><td style=\"text-align: right;\">nan      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " H2O automl leader performace :  Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_grid_0_AutoML_20180106_114457_model_0\n",
      "\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.2092739854208654\n",
      "RMSE: 0.45746473680587163\n",
      "MAE: 0.3363591570716453\n",
      "RMSLE: 0.14363654701704642\n",
      "Mean Residual Deviance: 0.2092739854208654\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.2357349406230617\n",
      "RMSE: 0.48552542737024773\n",
      "MAE: 0.35541663427237535\n",
      "RMSLE: 0.15117810160442893\n",
      "Mean Residual Deviance: 0.2357349406230617\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.23649265655078175\n",
      "RMSE: 0.48630510644119473\n",
      "MAE: 0.35692318661040956\n",
      "RMSLE: 0.151858739172448\n",
      "Mean Residual Deviance: 0.23649265655078175\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>mae</td>\n",
       "<td>0.3569232</td>\n",
       "<td>0.0004760</td>\n",
       "<td>0.3562465</td>\n",
       "<td>0.3561569</td>\n",
       "<td>0.3578717</td>\n",
       "<td>0.3568555</td>\n",
       "<td>0.3574853</td></tr>\n",
       "<tr><td>mean_residual_deviance</td>\n",
       "<td>0.2364927</td>\n",
       "<td>0.0006707</td>\n",
       "<td>0.2355622</td>\n",
       "<td>0.23739</td>\n",
       "<td>0.2372595</td>\n",
       "<td>0.2351332</td>\n",
       "<td>0.2371185</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.2364927</td>\n",
       "<td>0.0006707</td>\n",
       "<td>0.2355622</td>\n",
       "<td>0.23739</td>\n",
       "<td>0.2372595</td>\n",
       "<td>0.2351332</td>\n",
       "<td>0.2371185</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.6382779</td>\n",
       "<td>0.0015821</td>\n",
       "<td>0.6357610</td>\n",
       "<td>0.640187</td>\n",
       "<td>0.6399802</td>\n",
       "<td>0.6401342</td>\n",
       "<td>0.6353273</td></tr>\n",
       "<tr><td>residual_deviance</td>\n",
       "<td>0.2364927</td>\n",
       "<td>0.0006707</td>\n",
       "<td>0.2355622</td>\n",
       "<td>0.23739</td>\n",
       "<td>0.2372595</td>\n",
       "<td>0.2351332</td>\n",
       "<td>0.2371185</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.4863041</td>\n",
       "<td>0.0006899</td>\n",
       "<td>0.4853475</td>\n",
       "<td>0.4872268</td>\n",
       "<td>0.4870929</td>\n",
       "<td>0.4849053</td>\n",
       "<td>0.4869481</td></tr>\n",
       "<tr><td>rmsle</td>\n",
       "<td>0.1518571</td>\n",
       "<td>0.0004912</td>\n",
       "<td>0.1514123</td>\n",
       "<td>0.1525651</td>\n",
       "<td>0.1520299</td>\n",
       "<td>0.1507479</td>\n",
       "<td>0.1525306</td></tr></table></div>"
      ],
      "text/plain": [
       "                        mean      sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "----------------------  --------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "mae                     0.356923  0.000475961  0.356247      0.356157      0.357872      0.356855      0.357485\n",
       "mean_residual_deviance  0.236493  0.000670733  0.235562      0.23739       0.237259      0.235133      0.237118\n",
       "mse                     0.236493  0.000670733  0.235562      0.23739       0.237259      0.235133      0.237118\n",
       "r2                      0.638278  0.00158207   0.635761      0.640187      0.63998       0.640134      0.635327\n",
       "residual_deviance       0.236493  0.000670733  0.235562      0.23739       0.237259      0.235133      0.237118\n",
       "rmse                    0.486304  0.000689931  0.485347      0.487227      0.487093      0.484905      0.486948\n",
       "rmsle                   0.151857  0.00049121   0.151412      0.152565      0.15203       0.150748      0.152531"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_mae</b></td>\n",
       "<td><b>training_deviance</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_mae</b></td>\n",
       "<td><b>validation_deviance</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-01-06 12:24:02</td>\n",
       "<td> 4 min 58.377 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8085958</td>\n",
       "<td>0.6529881</td>\n",
       "<td>0.6538271</td>\n",
       "<td>0.8042427</td>\n",
       "<td>0.6475746</td>\n",
       "<td>0.6468063</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-01-06 12:24:04</td>\n",
       "<td> 5 min  0.101 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.6339973</td>\n",
       "<td>0.4991455</td>\n",
       "<td>0.4019525</td>\n",
       "<td>0.6335984</td>\n",
       "<td>0.4968915</td>\n",
       "<td>0.4014470</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-01-06 12:24:06</td>\n",
       "<td> 5 min  1.845 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.5560143</td>\n",
       "<td>0.4271737</td>\n",
       "<td>0.3091519</td>\n",
       "<td>0.5586335</td>\n",
       "<td>0.4275253</td>\n",
       "<td>0.3120714</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-01-06 12:24:07</td>\n",
       "<td> 5 min  3.602 sec</td>\n",
       "<td>15.0</td>\n",
       "<td>0.5227525</td>\n",
       "<td>0.3945118</td>\n",
       "<td>0.2732702</td>\n",
       "<td>0.5281891</td>\n",
       "<td>0.3972433</td>\n",
       "<td>0.2789837</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-01-06 12:24:09</td>\n",
       "<td> 5 min  5.255 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.5078149</td>\n",
       "<td>0.3794053</td>\n",
       "<td>0.2578760</td>\n",
       "<td>0.5155647</td>\n",
       "<td>0.3841296</td>\n",
       "<td>0.2658069</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-01-06 12:24:44</td>\n",
       "<td> 5 min 40.296 sec</td>\n",
       "<td>125.0</td>\n",
       "<td>0.4602994</td>\n",
       "<td>0.3384968</td>\n",
       "<td>0.2118755</td>\n",
       "<td>0.4865551</td>\n",
       "<td>0.3562154</td>\n",
       "<td>0.2367359</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-01-06 12:24:46</td>\n",
       "<td> 5 min 41.895 sec</td>\n",
       "<td>130.0</td>\n",
       "<td>0.4595106</td>\n",
       "<td>0.3378919</td>\n",
       "<td>0.2111500</td>\n",
       "<td>0.4862705</td>\n",
       "<td>0.3559921</td>\n",
       "<td>0.2364590</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-01-06 12:24:47</td>\n",
       "<td> 5 min 43.483 sec</td>\n",
       "<td>135.0</td>\n",
       "<td>0.4588862</td>\n",
       "<td>0.3374264</td>\n",
       "<td>0.2105766</td>\n",
       "<td>0.4859306</td>\n",
       "<td>0.3557362</td>\n",
       "<td>0.2361285</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-01-06 12:24:49</td>\n",
       "<td> 5 min 45.119 sec</td>\n",
       "<td>140.0</td>\n",
       "<td>0.4581092</td>\n",
       "<td>0.3368269</td>\n",
       "<td>0.2098640</td>\n",
       "<td>0.4855766</td>\n",
       "<td>0.3554501</td>\n",
       "<td>0.2357846</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-01-06 12:24:50</td>\n",
       "<td> 5 min 46.692 sec</td>\n",
       "<td>145.0</td>\n",
       "<td>0.4574647</td>\n",
       "<td>0.3363592</td>\n",
       "<td>0.2092740</td>\n",
       "<td>0.4855254</td>\n",
       "<td>0.3554166</td>\n",
       "<td>0.2357349</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration          number_of_trees    training_rmse        training_mae         training_deviance    validation_rmse      validation_mae       validation_deviance\n",
       "---  -------------------  ----------------  -----------------  -------------------  -------------------  -------------------  -------------------  -------------------  ---------------------\n",
       "     2018-01-06 12:24:02  4 min 58.377 sec  0.0                0.8085957679427576   0.6529881193668072   0.6538271159349378   0.8042427057130137   0.6475746042177135   0.6468063296925892\n",
       "     2018-01-06 12:24:04  5 min  0.101 sec  5.0                0.6339972767650924   0.499145463334097    0.40195254694555316  0.6335984186495853   0.4968914511483165   0.40144695611525516\n",
       "     2018-01-06 12:24:06  5 min  1.845 sec  10.0               0.5560142538146143   0.42717371950366084  0.3091518504450224   0.5586335018823015   0.4275252729221541   0.3120713894252834\n",
       "     2018-01-06 12:24:07  5 min  3.602 sec  15.0               0.5227524814460863   0.39451176479370964  0.2732701568580408   0.5281891042801514   0.3972433242465875   0.2789837298802687\n",
       "     2018-01-06 12:24:09  5 min  5.255 sec  20.0               0.5078149208515255   0.37940534970420614  0.25787599383944104  0.5155646653434487   0.38412960984989386  0.2658069241507023\n",
       "---  ---                  ---               ---                ---                  ---                  ---                  ---                  ---                  ---\n",
       "     2018-01-06 12:24:44  5 min 40.296 sec  125.0              0.46029936026606155  0.3384968469118708   0.21187550106134553  0.48655508698203576  0.35621539007360514  0.23673585266809638\n",
       "     2018-01-06 12:24:46  5 min 41.895 sec  130.0              0.45951061229966567  0.33789185627554635  0.21115000281601365  0.48627050551561307  0.35599212894793064  0.23645900453440988\n",
       "     2018-01-06 12:24:47  5 min 43.483 sec  135.0              0.4588862399040045   0.33742643439912423  0.21057658117323558  0.4859305559884725   0.3557361641637642   0.23612850524326603\n",
       "     2018-01-06 12:24:49  5 min 45.119 sec  140.0              0.4581091975407425   0.3368269185581472   0.20986403687142302  0.4855765966746907   0.3554501238914889   0.23578463123817525\n",
       "     2018-01-06 12:24:50  5 min 46.692 sec  145.0              0.45746473680587163  0.3363591570716453   0.2092739854208654   0.48552542737024773  0.35541663427237535  0.2357349406230617"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>median_visitors</td>\n",
       "<td>258507.9218750</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5817699</td></tr>\n",
       "<tr><td>mean_visitors</td>\n",
       "<td>97044.7109375</td>\n",
       "<td>0.3754032</td>\n",
       "<td>0.2183983</td></tr>\n",
       "<tr><td>air_store_id</td>\n",
       "<td>60874.5859375</td>\n",
       "<td>0.2354844</td>\n",
       "<td>0.1369977</td></tr>\n",
       "<tr><td>rv1_x</td>\n",
       "<td>7631.5859375</td>\n",
       "<td>0.0295217</td>\n",
       "<td>0.0171748</td></tr>\n",
       "<tr><td>visit_date</td>\n",
       "<td>4052.9213867</td>\n",
       "<td>0.0156781</td>\n",
       "<td>0.0091211</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>var_max_long</td>\n",
       "<td>29.0221043</td>\n",
       "<td>0.0001123</td>\n",
       "<td>0.0000653</td></tr>\n",
       "<tr><td>latitude</td>\n",
       "<td>24.8392525</td>\n",
       "<td>0.0000961</td>\n",
       "<td>0.0000559</td></tr>\n",
       "<tr><td>air_area_name1</td>\n",
       "<td>23.7142143</td>\n",
       "<td>0.0000917</td>\n",
       "<td>0.0000534</td></tr>\n",
       "<tr><td>total_reserv_dt_diff_mean</td>\n",
       "<td>14.7305527</td>\n",
       "<td>0.0000570</td>\n",
       "<td>0.0000332</td></tr>\n",
       "<tr><td>air_genre_name2</td>\n",
       "<td>1.4050379</td>\n",
       "<td>0.0000054</td>\n",
       "<td>0.0000032</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                   relative_importance    scaled_importance       percentage\n",
       "-------------------------  ---------------------  ----------------------  ----------------------\n",
       "median_visitors            258507.921875          1.0                     0.5817698651578044\n",
       "mean_visitors              97044.7109375          0.3754032380656613      0.21839829118926293\n",
       "air_store_id               60874.5859375          0.23548441183529978     0.13699773452018724\n",
       "rv1_x                      7631.5859375           0.029521671452645885    0.017174818820238802\n",
       "visit_date                 4052.92138671875       0.01567813224957383     0.009121064884760792\n",
       "---                        ---                    ---                     ---\n",
       "var_max_long               29.022104263305664     0.00011226775586915721  6.531399719356889e-05\n",
       "latitude                   24.839252471923828     9.60870068961937e-05    5.5900525045415636e-05\n",
       "air_area_name1             23.714214324951172     9.173496174874688e-05   5.336863632682482e-05\n",
       "total_reserv_dt_diff_mean  14.730552673339844     5.698298360257879e-05   3.315098268676164e-05\n",
       "air_genre_name2            1.4050378799438477     5.435183068096635e-06   3.1620257206345608e-06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from hklee\n",
    "# https://www.kaggle.com/zeemeen/weighted-mean-comparisons-lb-0-497-1st/code\n",
    "dfs = { re.search('/([^/\\.]*)\\.csv', fn).group(1):\n",
    "    pd.read_csv(fn)for fn in glob.glob('../input/*.csv')}\n",
    "\n",
    "for k, v in dfs.items(): locals()[k] = v\n",
    "\n",
    "wkend_holidays = date_info.apply(\n",
    "    (lambda x:(x.day_of_week=='Sunday' or x.day_of_week=='Saturday') and x.holiday_flg==1), axis=1)\n",
    "date_info.loc[wkend_holidays, 'holiday_flg'] = 0\n",
    "date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5  \n",
    "\n",
    "visit_data = air_visit_data.merge(date_info, left_on='visit_date', right_on='calendar_date', how='left')\n",
    "visit_data.drop('calendar_date', axis=1, inplace=True)\n",
    "visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)\n",
    "\n",
    "wmean = lambda x:( (x.weight * x.visitors).sum() / x.weight.sum() )\n",
    "visitors = visit_data.groupby(['air_store_id', 'day_of_week', 'holiday_flg']).apply(wmean).reset_index()\n",
    "visitors.rename(columns={0:'visitors'}, inplace=True) # cumbersome, should be better ways.\n",
    "\n",
    "sample_submission['air_store_id'] = sample_submission.id.map(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "sample_submission['calendar_date'] = sample_submission.id.map(lambda x: x.split('_')[2])\n",
    "sample_submission.drop('visitors', axis=1, inplace=True)\n",
    "sample_submission = sample_submission.merge(date_info, on='calendar_date', how='left')\n",
    "sample_submission = sample_submission.merge(visitors, on=[\n",
    "    'air_store_id', 'day_of_week', 'holiday_flg'], how='left')\n",
    "\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(\n",
    "    visitors[visitors.holiday_flg==0], on=('air_store_id', 'day_of_week'), \n",
    "    how='left')['visitors_y'].values\n",
    "\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(\n",
    "    visitors[['air_store_id', 'visitors']].groupby('air_store_id').mean().reset_index(), \n",
    "    on='air_store_id', how='left')['visitors_y'].values\n",
    "\n",
    "sample_submission['visitors'] = sample_submission.visitors.map(pd.np.expm1)\n",
    "sub2 = sample_submission[['id', 'visitors']].copy()\n",
    "sub_merge = pd.merge(sub1, sub2, on='id', how='inner')\n",
    "\n",
    "sub_merge['visitors'] = (sub_merge['visitors_x'] + sub_merge['visitors_y']* 1.1)/2\n",
    "sub_merge[['id', 'visitors']].to_csv('submission.csv', index=False)\n",
    "\n",
    "print('Leaderboard : ', aml.leaderboard)\n",
    "\n",
    "print(' H2O automl leader performace : ', aml.leader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
